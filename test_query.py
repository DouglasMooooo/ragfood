import os
import json
import numpy as np
from dotenv import load_dotenv
from upstash_vector import Index
from groq import Groq
from sentence_transformers import SentenceTransformer

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# åˆå§‹åŒ–
model = SentenceTransformer("all-MiniLM-L6-v2")
groq_client = Groq(api_key=os.getenv("GROQ_API_KEY", ""))
index = Index(
    url=os.getenv("UPSTASH_VECTOR_REST_URL"),
    token=os.getenv("UPSTASH_VECTOR_REST_TOKEN")
)

def create_embedding(text: str):
    """ç”Ÿæˆ 384ç»´åµŒå…¥å¹¶è¡¥é½åˆ° 1024ç»´"""
    emb = model.encode(text)
    padded = np.pad(emb, (0, 1024 - len(emb)), 'constant')
    return padded.tolist()

def query_upstash(query_text, top_k=5, threshold=0.1):
    """æŸ¥è¯¢æœ€ç›¸ä¼¼çš„å‘é‡"""
    query_vector = create_embedding(query_text)

    try:
        results = index.query(
            vector=query_vector,
            top_k=top_k,
            include_metadata=True,
            include_vectors=False
        )
    except Exception as e:
        print("âŒ Query failed:", e)
        return []

    # ç»Ÿä¸€å…¼å®¹è¿”å›ç»“æ„ - ä¿®å¤å
    matches = []
    if isinstance(results, list):
        # Upstash ç›´æ¥è¿”å›åˆ—è¡¨
        matches = results
    elif isinstance(results, dict):
        matches = results.get("matches", [])
    elif hasattr(results, "matches"):
        matches = results.matches

    if not matches:
        print("âš ï¸ No relevant context found (empty).")
        return []

    # æ‰“å°è°ƒè¯•ä¿¡æ¯
    print(f"\nğŸ” Found {len(matches)} results:")
    for m in matches:
        score = getattr(m, "score", 0)
        print(f"  ID: {m.id}, Score: {score:.4f}")

    # è¿‡æ»¤ç›¸ä¼¼åº¦ä½çš„é¡¹
    valid = [m for m in matches if getattr(m, "score", 0) > threshold]
    if not valid:
        print(f"âš ï¸ No relevant context found (all scores below threshold {threshold}).")
        return []

    return valid

def ask_groq(question, context):
    """æŠŠä¸Šä¸‹æ–‡ + é—®é¢˜äº¤ç»™ Groq æ¨¡å‹"""
    prompt = f"""
You are a food expert AI. Use only the provided context to answer.

Context:
{context}

Question: {question}
Answer:
"""
    try:
        resp = groq_client.chat.completions.create(
            model="llama-3.1-8b-instant",
            messages=[{"role": "user", "content": prompt}]
        )
        return resp.choices[0].message.content.strip()
    except Exception as e:
        return f"âš ï¸ Groq error: {e}"

# æµ‹è¯•æŸ¥è¯¢
print("=" * 60)
print("ğŸ§ª æµ‹è¯• RAG æŸ¥è¯¢")
print("=" * 60)

question = "I wanna eat some Asian food today"
print(f"\nâ“ Question: {question}")

results = query_upstash(question)

if results:
    # æ‹¼æ¥ä¸Šä¸‹æ–‡
    context_items = []
    for r in results:
        text = r.metadata.get('text', 'No description available')
        region = r.metadata.get('region', 'Unknown')
        food_type = r.metadata.get('type', 'Unknown')
        context_items.append(f"[{region} - {food_type}] {text}")
    
    context = "\n".join(context_items)
    print("\nğŸ§  Retrieved context:")
    print(context)

    print("\nğŸ’¬ Asking Groq...")
    answer = ask_groq(question, context)
    print("\nâœ… Groq Answer:")
    print(answer)
else:
    print("\nâŒ No results found")

print("\n" + "=" * 60)
