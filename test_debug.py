import os
import json
import numpy as np
from dotenv import load_dotenv
from upstash_vector import Index
from sentence_transformers import SentenceTransformer

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# åˆå§‹åŒ–
model = SentenceTransformer("all-MiniLM-L6-v2")
index = Index(
    url=os.getenv("UPSTASH_VECTOR_REST_URL"),
    token=os.getenv("UPSTASH_VECTOR_REST_TOKEN")
)

def create_embedding(text: str):
    """ç”Ÿæˆ 384ç»´åµŒå…¥å¹¶è¡¥é½åˆ° 1024ç»´"""
    emb = model.encode(text)
    padded = np.pad(emb, (0, 1024 - len(emb)), 'constant')
    return padded.tolist()

print("=" * 60)
print("ğŸ” RAG è¯Šæ–­æµ‹è¯•")
print("=" * 60)

# æµ‹è¯•1: æ£€æŸ¥å‘é‡ç»´åº¦
print("\n1ï¸âƒ£ æµ‹è¯•å‘é‡ç”Ÿæˆ:")
test_text = "I want to eat Asian food"
test_vector = create_embedding(test_text)
print(f"   æ–‡æœ¬: {test_text}")
print(f"   å‘é‡ç»´åº¦: {len(test_vector)}")
print(f"   å‘é‡å‰5ä¸ªå€¼: {test_vector[:5]}")

# æµ‹è¯•2: å°è¯•æŸ¥è¯¢ Upstash
print("\n2ï¸âƒ£ æµ‹è¯• Upstash æŸ¥è¯¢:")
try:
    results = index.query(
        vector=test_vector,
        top_k=5,
        include_metadata=True,
        include_vectors=False
    )
    
    print(f"   æŸ¥è¯¢æˆåŠŸ!")
    print(f"   è¿”å›ç±»å‹: {type(results)}")
    
    # æ£€æŸ¥è¿”å›ç»“æ„
    if isinstance(results, dict):
        print(f"   ç»“æœæ˜¯å­—å…¸ï¼Œkeys: {results.keys()}")
        matches = results.get("matches", [])
    elif hasattr(results, "matches"):
        print(f"   ç»“æœæœ‰ matches å±æ€§")
        matches = results.matches
    else:
        print(f"   æœªçŸ¥ç»“æ„: {results}")
        matches = []
    
    print(f"   åŒ¹é…æ•°é‡: {len(matches)}")
    
    if matches:
        print(f"\n   âœ… æ‰¾åˆ° {len(matches)} ä¸ªç»“æœ:")
        for i, m in enumerate(matches[:3]):
            score = getattr(m, "score", 0)
            print(f"      [{i+1}] ID: {m.id}, Score: {score:.4f}")
            if hasattr(m, 'metadata'):
                print(f"          Metadata keys: {m.metadata.keys() if m.metadata else 'None'}")
                if m.metadata:
                    print(f"          Region: {m.metadata.get('region', 'N/A')}")
                    print(f"          Type: {m.metadata.get('type', 'N/A')}")
                    text = m.metadata.get('text', 'N/A')
                    print(f"          Text: {text[:80]}..." if len(text) > 80 else f"          Text: {text}")
    else:
        print("   âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•åŒ¹é…ç»“æœ (empty)")
        
except Exception as e:
    print(f"   âŒ æŸ¥è¯¢å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()

# æµ‹è¯•3: æ£€æŸ¥ Upstash ç´¢å¼•ä¿¡æ¯
print("\n3ï¸âƒ£ æµ‹è¯•ç´¢å¼•ä¿¡æ¯:")
try:
    info = index.info()
    print(f"   ç´¢å¼•ä¿¡æ¯: {info}")
except Exception as e:
    print(f"   è·å–ç´¢å¼•ä¿¡æ¯å¤±è´¥: {e}")

# æµ‹è¯•4: å°è¯•è·å–ä¸€ä¸ªå·²çŸ¥ID
print("\n4ï¸âƒ£ æµ‹è¯•è·å–å•ä¸ªå‘é‡ (ID=1):")
try:
    fetch_result = index.fetch(ids=["1"], include_metadata=True)
    print(f"   Fetch ç»“æœç±»å‹: {type(fetch_result)}")
    print(f"   Fetch ç»“æœ: {fetch_result}")
    if fetch_result:
        print(f"   âœ… æˆåŠŸè·å– ID=1 çš„æ•°æ®")
        if len(fetch_result) > 0:
            item = fetch_result[0]
            print(f"      Metadata: {item.metadata if hasattr(item, 'metadata') else 'N/A'}")
    else:
        print(f"   âš ï¸ ID=1 ä¸å­˜åœ¨ï¼Œæ•°æ®åº“å¯èƒ½æ˜¯ç©ºçš„")
except Exception as e:
    print(f"   âŒ Fetch å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()

print("\n" + "=" * 60)
print("è¯Šæ–­å®Œæˆ!")
print("=" * 60)
